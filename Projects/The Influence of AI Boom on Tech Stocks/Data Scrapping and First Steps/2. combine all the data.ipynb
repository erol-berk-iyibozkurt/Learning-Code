{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meta data of the top 100 tech companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Marketcap and Currency Info datasets loaded successfully.\n",
      "✅ Metadata for top 100 companies saved to /Users/erolberkiyibozkurt/Documents/GitHub/Python/Projects/The Influence of AI Boom on Tech Stocks/Background Data/stock_metadata_top100.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 1: LOAD REQUIRED DATA\n",
    "# -------------------------------\n",
    "\n",
    "# File paths\n",
    "marketcap_path = \"/Users/erolberkiyibozkurt/Documents/GitHub/Python/Projects/The Influence of AI Boom on Tech Stocks/Background Data/companiesmarketcap.com - Largest tech companies by market cap.csv\"\n",
    "currency_info_path = \"/Users/erolberkiyibozkurt/Documents/GitHub/Python/Projects/The Influence of AI Boom on Tech Stocks/Background Data/stock_exchange_currency_info.csv\"\n",
    "metadata_output_path = \"/Users/erolberkiyibozkurt/Documents/GitHub/Python/Projects/The Influence of AI Boom on Tech Stocks/Background Data/stock_metadata_top100.csv\"\n",
    "\n",
    "# Load datasets\n",
    "marketcap_df = pd.read_csv(marketcap_path)\n",
    "currency_info_df = pd.read_csv(currency_info_path)\n",
    "\n",
    "print(\"✅ Marketcap and Currency Info datasets loaded successfully.\")\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 2: SELECT TOP 100 COMPANIES\n",
    "# -------------------------------\n",
    "\n",
    "# Select the top 100 companies\n",
    "marketcap_top100 = marketcap_df.head(100)[['Rank', 'Name', 'Symbol']].drop_duplicates(subset='Symbol')\n",
    "\n",
    "# Check for missing essential columns in currency info\n",
    "required_currency_columns = ['Symbol', 'Exchange', 'Currency', 'Country']\n",
    "for col in required_currency_columns:\n",
    "    if col not in currency_info_df.columns:\n",
    "        print(f\"⚠️ Column '{col}' is missing in currency_info dataset. Adding default value 'Unknown'.\")\n",
    "        currency_info_df[col] = 'Unknown'\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 3: MERGE DATASETS\n",
    "# -------------------------------\n",
    "\n",
    "# Merge top 100 companies with currency and exchange info\n",
    "metadata_top100 = marketcap_top100.merge(\n",
    "    currency_info_df[['Symbol', 'Exchange', 'Currency', 'Country']],\n",
    "    on='Symbol',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing values with 'Unknown'\n",
    "metadata_top100[['Exchange', 'Currency', 'Country']] = metadata_top100[['Exchange', 'Currency', 'Country']].fillna('Unknown')\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 4: SAVE METADATA FILE\n",
    "# -------------------------------\n",
    "\n",
    "# Save metadata for top 100 companies to CSV\n",
    "metadata_top100.to_csv(metadata_output_path, index=False)\n",
    "print(f\"✅ Metadata for top 100 companies saved to {metadata_output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data without currency changing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g1/lmg3w4rs5t7f4c_vswsjfrz80000gn/T/ipykernel_7916/3045492590.py:18: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  forex_df = pd.read_csv(forex_path, index_col=0, parse_dates=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Metadata and Forex data loaded successfully.\n",
      "✅ Currency conversion applied successfully.\n",
      "✅ Time series data for top 100 companies saved to /Users/erolberkiyibozkurt/Documents/GitHub/Python/Projects/The Influence of AI Boom on Tech Stocks/Background Data/stock_timeseries_top100.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 1: LOAD REQUIRED DATA\n",
    "# -------------------------------\n",
    "\n",
    "# File paths\n",
    "metadata_path = \"/Users/erolberkiyibozkurt/Documents/GitHub/Python/Projects/The Influence of AI Boom on Tech Stocks/Background Data/stock_metadata_top100.csv\"\n",
    "forex_path = \"/Users/erolberkiyibozkurt/Documents/GitHub/Python/Projects/The Influence of AI Boom on Tech Stocks/Background Data/forex_rates.csv\"\n",
    "data_path = \"/Users/erolberkiyibozkurt/Documents/GitHub/Python/Projects/The Influence of AI Boom on Tech Stocks/Data_of_biggest_100_companies/*.csv\"\n",
    "timeseries_output_path = \"/Users/erolberkiyibozkurt/Documents/GitHub/Python/Projects/The Influence of AI Boom on Tech Stocks/Background Data/stock_timeseries_top100.csv\"\n",
    "\n",
    "# Load datasets\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "forex_df = pd.read_csv(forex_path, index_col=0, parse_dates=True)\n",
    "\n",
    "print(\"✅ Metadata and Forex data loaded successfully.\")\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 2: LOAD AND COMBINE TIME SERIES DATA\n",
    "# -------------------------------\n",
    "\n",
    "# Load stock data files for top 100 symbols\n",
    "all_files = glob.glob(data_path)\n",
    "combined_data = []\n",
    "\n",
    "# Filter only top 100 symbols\n",
    "top100_symbols = metadata_df['Symbol'].unique()\n",
    "\n",
    "for file in all_files:\n",
    "    symbol = os.path.basename(file).split('_')[0]\n",
    "    if symbol in top100_symbols:\n",
    "        df = pd.read_csv(file)\n",
    "        df['Symbol'] = symbol\n",
    "        df = df[['Date', 'Adj Close', 'Close', 'High', 'Low', 'Open', 'Volume', 'Symbol']]\n",
    "        combined_data.append(df)\n",
    "\n",
    "# Combine all data into one DataFrame\n",
    "timeseries_df = pd.concat(combined_data, ignore_index=True)\n",
    "timeseries_df['Date'] = pd.to_datetime(timeseries_df['Date'], errors='coerce')\n",
    "\n",
    "# Merge currency info from metadata\n",
    "timeseries_df = timeseries_df.merge(\n",
    "    metadata_df[['Symbol', 'Currency']],\n",
    "    on='Symbol',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 3: APPLY CURRENCY CONVERSION\n",
    "# -------------------------------\n",
    "\n",
    "# Add USD columns\n",
    "for col in ['Adj Close', 'Close', 'High', 'Low', 'Open']:\n",
    "    timeseries_df[f'USD_{col}'] = timeseries_df[col]\n",
    "\n",
    "# Convert non-USD values\n",
    "non_usd_mask = timeseries_df['Currency'] != 'USD'\n",
    "non_usd_df = timeseries_df[non_usd_mask]\n",
    "\n",
    "if not non_usd_df.empty:\n",
    "    for currency in non_usd_df['Currency'].unique():\n",
    "        forex_pair = f\"{currency}USD=X\"\n",
    "        if forex_pair in forex_df.columns:\n",
    "            for date, group in non_usd_df.groupby('Date'):\n",
    "                if date in forex_df.index:\n",
    "                    conversion_rate = forex_df.at[date, forex_pair]\n",
    "                    mask = (timeseries_df['Date'] == date) & (timeseries_df['Currency'] == currency)\n",
    "                    for col in ['Adj Close', 'Close', 'High', 'Low', 'Open']:\n",
    "                        usd_col = f'USD_{col}'\n",
    "                        timeseries_df.loc[mask, usd_col] = timeseries_df.loc[mask, col] * conversion_rate\n",
    "\n",
    "print(\"✅ Currency conversion applied successfully.\")\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 4: SAVE TIME SERIES FILE\n",
    "# -------------------------------\n",
    "\n",
    "# Select final columns\n",
    "final_columns = ['Date', 'Symbol', 'USD_Adj Close', 'USD_Close', 'USD_High', 'Low', 'USD_Low', 'USD_Open', 'Volume']\n",
    "timeseries_df = timeseries_df[final_columns]\n",
    "\n",
    "# Save the final time series data\n",
    "timeseries_df.to_csv(timeseries_output_path, index=False)\n",
    "print(f\"✅ Time series data for top 100 companies saved to {timeseries_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g1/lmg3w4rs5t7f4c_vswsjfrz80000gn/T/ipykernel_7916/3617233408.py:19: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  forex_df = pd.read_csv(forex_path, index_col=0, parse_dates=True)\n",
      "/var/folders/g1/lmg3w4rs5t7f4c_vswsjfrz80000gn/T/ipykernel_7916/3617233408.py:29: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  forex_df.index = pd.to_datetime(forex_df.index, errors='coerce').date\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Metadata, Forex, and Currency Info data loaded successfully.\n",
      "✅ Currency conversion applied successfully.\n",
      "✅ Time series data for top 100 companies saved to /Users/erolberkiyibozkurt/Documents/GitHub/Python/Projects/The Influence of AI Boom on Tech Stocks/Background Data/stock_timeseries_top100.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 1: LOAD REQUIRED DATA\n",
    "# -------------------------------\n",
    "\n",
    "# File paths\n",
    "metadata_path = \"/Users/erolberkiyibozkurt/Documents/GitHub/Python/Projects/The Influence of AI Boom on Tech Stocks/Background Data/stock_metadata_top100.csv\"\n",
    "forex_path = \"/Users/erolberkiyibozkurt/Documents/GitHub/Python/Projects/The Influence of AI Boom on Tech Stocks/Background Data/forex_rates.csv\"\n",
    "currency_info_path = \"/Users/erolberkiyibozkurt/Documents/GitHub/Python/Projects/The Influence of AI Boom on Tech Stocks/Background Data/stock_exchange_currency_info.csv\"\n",
    "data_path = \"/Users/erolberkiyibozkurt/Documents/GitHub/Python/Projects/The Influence of AI Boom on Tech Stocks/Data_of_biggest_100_companies/*.csv\"\n",
    "timeseries_output_path = \"/Users/erolberkiyibozkurt/Documents/GitHub/Python/Projects/The Influence of AI Boom on Tech Stocks/Background Data/stock_timeseries_top100.csv\"\n",
    "\n",
    "# Load datasets\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "forex_df = pd.read_csv(forex_path, index_col=0, parse_dates=True)\n",
    "currency_info_df = pd.read_csv(currency_info_path)\n",
    "\n",
    "print(\"✅ Metadata, Forex, and Currency Info data loaded successfully.\")\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 2: FORMAT DATES AND CLEAN DATA\n",
    "# -------------------------------\n",
    "\n",
    "# Tarih formatını standart hale getir\n",
    "forex_df.index = pd.to_datetime(forex_df.index, errors='coerce').date\n",
    "metadata_df['Symbol'] = metadata_df['Symbol'].astype(str)\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 3: LOAD AND COMBINE TIME SERIES DATA\n",
    "# -------------------------------\n",
    "\n",
    "# Load stock data files for top 100 symbols\n",
    "all_files = glob.glob(data_path)\n",
    "combined_data = []\n",
    "\n",
    "# Filter only top 100 symbols\n",
    "top100_symbols = metadata_df['Symbol'].unique()\n",
    "\n",
    "for file in all_files:\n",
    "    symbol = os.path.basename(file).split('_')[0]\n",
    "    if symbol in top100_symbols:\n",
    "        df = pd.read_csv(file)\n",
    "        df['Symbol'] = symbol\n",
    "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce').dt.date\n",
    "        df = df[['Symbol', 'Date', 'Adj Close', 'Close', 'High', 'Low', 'Open', 'Volume']]\n",
    "        combined_data.append(df)\n",
    "\n",
    "# Combine all data into one DataFrame\n",
    "timeseries_df = pd.concat(combined_data, ignore_index=True)\n",
    "timeseries_df['Date'] = pd.to_datetime(timeseries_df['Date'], errors='coerce').dt.date\n",
    "timeseries_df.sort_values(by=['Date', 'Symbol'], inplace=True)\n",
    "timeseries_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Merge currency info from metadata\n",
    "timeseries_df = timeseries_df.merge(\n",
    "    metadata_df[['Symbol', 'Currency']],\n",
    "    on='Symbol',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 4: CLEAN AND VALIDATE DATA TYPES\n",
    "# -------------------------------\n",
    "\n",
    "# Sayısal sütunları float türüne dönüştür\n",
    "for col in ['Adj Close', 'Close', 'High', 'Low', 'Open']:\n",
    "    timeseries_df[col] = pd.to_numeric(timeseries_df[col], errors='coerce')\n",
    "\n",
    "# USD sütunlarını baştan oluştur\n",
    "for col in ['Adj Close', 'Close', 'High', 'Low', 'Open']:\n",
    "    timeseries_df[f'USD_{col}'] = np.nan\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 5: APPLY CURRENCY CONVERSION\n",
    "# -------------------------------\n",
    "\n",
    "# Döviz dönüşümü\n",
    "for currency, forex_pair in {\n",
    "    'KRW': 'KRWUSD=X',\n",
    "    'HKD': 'HKDUSD=X',\n",
    "    'EUR': 'EURUSD=X',\n",
    "    'JPY': 'JPYUSD=X',\n",
    "    'ILS': 'ILSUSD=X',\n",
    "    'TWD': 'TWDUSD=X',\n",
    "    'CAD': 'CADUSD=X',\n",
    "    'THB': 'THBUSD=X'\n",
    "}.items():\n",
    "    if forex_pair in forex_df.columns:\n",
    "        valid_dates = forex_df.index.intersection(timeseries_df['Date'].dropna().unique())\n",
    "        conversion_rates = forex_df.loc[valid_dates, forex_pair].to_dict()\n",
    "        \n",
    "        for date in valid_dates:\n",
    "            mask = (timeseries_df['Date'] == date) & (timeseries_df['Currency'] == currency)\n",
    "            conversion_rate = conversion_rates.get(date)\n",
    "            \n",
    "            if pd.notnull(conversion_rate):\n",
    "                for col in ['Adj Close', 'Close', 'High', 'Low', 'Open']:\n",
    "                    usd_col = f'USD_{col}'\n",
    "                    timeseries_df.loc[mask, usd_col] = timeseries_df.loc[mask, col].astype(float) * float(conversion_rate)\n",
    "\n",
    "# USD olan değerleri doğrudan taşı\n",
    "usd_mask = timeseries_df['Currency'] == 'USD'\n",
    "for col in ['Adj Close', 'Close', 'High', 'Low', 'Open']:\n",
    "    usd_col = f'USD_{col}'\n",
    "    timeseries_df.loc[usd_mask, usd_col] = timeseries_df.loc[usd_mask, col]\n",
    "\n",
    "print(\"✅ Currency conversion applied successfully.\")\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 6: FINAL FORMATTING & SAVE\n",
    "# -------------------------------\n",
    "\n",
    "# Nihai sütunlar\n",
    "final_columns = ['Symbol', 'Date', 'USD_Adj Close', 'USD_Close', 'USD_High', 'USD_Low', 'USD_Open', 'Volume']\n",
    "timeseries_df = timeseries_df[final_columns]\n",
    "\n",
    "# Tarih formatı son kontrol\n",
    "timeseries_df['Date'] = pd.to_datetime(timeseries_df['Date'], errors='coerce').dt.date\n",
    "\n",
    "# CSV dosyasını kaydet\n",
    "timeseries_df.to_csv(timeseries_output_path, index=False)\n",
    "print(f\"✅ Time series data for top 100 companies saved to {timeseries_output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
